Index: functions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nfrom variables import signal\n\n\ndef prepare_target(target):\n    for i in range(len(target)):\n        if target[i].item() == signal: #prepare target\n            target[i] = 1\n        else:\n            target[i] = 0\n    target = target.float()\n    return target\n\n\ndef subset_data(data,target,background):\n\n    target_counts = torch.unique(target,True,False,True) # 0 returns a list of the unique values in the target and 1 gives their number of occurences\n    len_subset = 0\n    if target_counts[0].shape[0] != 10:\n        print(\"SUSPICOUS OCURRENCE, not all numbers are present in the data\") #possibly becasue the batch size is just small\n\n    for i in range(target_counts[0].shape[0]): #find where the signal and background are\n        if target_counts[0][i] == signal or target_counts[0][i] == background:\n            len_subset += target_counts[1][i]\n    print(len_subset)\n\n\n    data_subset = torch.zeros(len_subset,1,28,28)\n    target_subset = torch.zeros(len_subset)\n\n    i =0\n    for j in range(target.shape[0]):\n        if target[j] == signal or target[j] == background:\n            data_subset[i] = data[j]\n            target_subset[i] = target[j]\n            i += 1\n    return data_subset,target_subset\n\n\n\n#data = torch.zeros(12,1,28,28)\n#for i in range(12):\n#    data_point = torch.full((1,28,28),i)\n#    data[i] = data_point\n#print(data[6])\n\n#data_subset,target_subset = subset_data(data, torch.tensor([1,2,4,6,7,8,4,2,3,4,7,7]),7)\n#print(data_subset)\n#print(target_subset)\n\n\n\n\n\n\ndef sig_loss(expectedSignal,expectedBackground):\n    def sigloss(y_true,y_pred):\n        signalWeight = expectedSignal/torch.sum(y_true)    #expected/actual signal numbers\n        backgroundWeight = expectedBackground/torch.sum(1-y_true)   #expected/actual background numbers\n        y_pred_rearanged = torch.reshape(y_pred,(-1,))\n        s = signalWeight*torch.sum(y_pred_rearanged*y_true)\n        b = backgroundWeight*torch.sum(y_pred_rearanged*(1-y_true))\n        return -(s*s)/(s+b+0.000001)\n    return sigloss\n\n\ndef significance_loss(target,output,using_full_dataset):\n    target = prepare_target(target)\n\n    if using_full_dataset:\n        sigloss = sig_loss(len(target)/10,9*len(target)/10)\n    else:\n        sigloss = sig_loss(len(target)/10,len(target)/10)\n\n    loss = sigloss(target,output)\n    return loss\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/functions.py b/functions.py
--- a/functions.py	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/functions.py	(date 1626907838536)
@@ -2,24 +2,24 @@
 from variables import signal
 
 
+
 def prepare_target(target):
     for i in range(len(target)):
-        if target[i].item() == signal: #prepare target
+        if target[i].item() == signal:
             target[i] = 1
         else:
             target[i] = 0
     target = target.float()
     return target
 
-
 def subset_data(data,target,background):
 
-    target_counts = torch.unique(target,True,False,True) # 0 returns a list of the unique values in the target and 1 gives their number of occurences
+    target_counts = torch.unique(target,True, False,True)
     len_subset = 0
     if target_counts[0].shape[0] != 10:
-        print("SUSPICOUS OCURRENCE, not all numbers are present in the data") #possibly becasue the batch size is just small
+        print("SUSPICIOUS OCCURENCE, not all numbers are present in the data")
 
-    for i in range(target_counts[0].shape[0]): #find where the signal and background are
+    for i in range(target_counts[0].shape[0]):
         if target_counts[0][i] == signal or target_counts[0][i] == background:
             len_subset += target_counts[1][i]
     print(len_subset)
@@ -28,49 +28,101 @@
     data_subset = torch.zeros(len_subset,1,28,28)
     target_subset = torch.zeros(len_subset)
 
-    i =0
-    for j in range(target.shape[0]):
-        if target[j] == signal or target[j] == background:
-            data_subset[i] = data[j]
-            target_subset[i] = target[j]
-            i += 1
-    return data_subset,target_subset
-
-
-
-#data = torch.zeros(12,1,28,28)
-#for i in range(12):
-#    data_point = torch.full((1,28,28),i)
-#    data[i] = data_point
-#print(data[6])
-
-#data_subset,target_subset = subset_data(data, torch.tensor([1,2,4,6,7,8,4,2,3,4,7,7]),7)
-#print(data_subset)
-#print(target_subset)
-
-
-
-
-
-
 def sig_loss(expectedSignal,expectedBackground):
     def sigloss(y_true,y_pred):
+
+        #print(expectedBackground)
+        #print(expectedSignal)
+        #print(expectedSignal)
         signalWeight = expectedSignal/torch.sum(y_true)    #expected/actual signal numbers
         backgroundWeight = expectedBackground/torch.sum(1-y_true)   #expected/actual background numbers
+        print("weights are {},{}".format(signalWeight,backgroundWeight))
+       # print(y_true)
+
         y_pred_rearanged = torch.reshape(y_pred,(-1,))
-        s = signalWeight*torch.sum(y_pred_rearanged*y_true)
-        b = backgroundWeight*torch.sum(y_pred_rearanged*(1-y_true))
+
+
+        #print(y_pred)
+        #print(y_pred_rearanged)
+        #print(y_pred_rearanged)
+        #print(y_pred*y_true)
+        #print(y_true*y_pred_rearanged)
+
+
+        s = torch.sum(y_pred_rearanged*y_true)
+        print("s")
+        print(s)
+        #print("s = {}".format(s))
+        b = torch.sum(y_pred_rearanged*(1-y_true))
+        print(b)
+        #print("b = {}".format(b))
+
+        #exp = torch.exp(-(s*s)/(s+b+ 0.000000001))
+        #scaled_exp = torch.exp(-(s*s)/(s+b+ 0.000000001))*10000000
         return -(s*s)/(s+b+0.000001)
     return sigloss
 
 
-def significance_loss(target,output,using_full_dataset):
-    target = prepare_target(target)
+
+def sig_loss2(expectedSignal,expectedBackground):
+    def sigloss(y_true,y_pred):
+        #print(expectedSignal)
+        #print(expectedBackground)
+        #print(expectedSignal)
+        signalWeight = expectedSignal/torch.sum(y_true)    #expected/actual signal numbers
+        backgroundWeight = expectedBackground/torch.sum(1-y_true)  #expected/actual background numbers
+
+        s = signalWeight*torch.sum(y_pred*y_true)
+        inverted_target_matrix = torch.zeros(y_true.size()[0],10)
+        for i in range(y_true.size()[0]):
+            if y_true[i][signal] ==0:
+                inverted_target_matrix[i][signal] = 1
+
+
+
+        b = backgroundWeight*torch.sum(y_pred*inverted_target_matrix)
+
+        #print("s {}".format(s))
+        #print("b {}".format(b))
+        #print("s+b {}".format(s+b))
+
+        #exp = torch.exp(-(s*s)/(s+b+ 0.000000001))
+        #scaled_exp = torch.exp(-(s*s)/(s+b+ 0.000000001))*10000000
+        return -(s*s)/(s+b+0.000001)
+    return sigloss
+
+
+
+
+
+
+def significance_loss2(target,output,batch_size):
+    torch.autograd.set_detect_anomaly(True)
+
+    target_matrix = torch.zeros(len(target),10)
+    for i in range(len(target)):
+        if target[i] == signal:
+            target_matrix[i][signal] = 1
+
+    sigloss = sig_loss2(batch_size/10,9*batch_size/10)
+    loss = sigloss(target_matrix,output)
+    return loss
+
 
-    if using_full_dataset:
-        sigloss = sig_loss(len(target)/10,9*len(target)/10)
-    else:
-        sigloss = sig_loss(len(target)/10,len(target)/10)
+
+
+def significance_loss(target,output,batch_size):
+    #print("significance loss called")
+    torch.autograd.set_detect_anomaly(True)
+
+
+    for i in range(len(target)):
+        if target[i] == signal:
+            target[i] = 1
+        else:
+            target[i] = 0
 
+    sigloss = sig_loss(batch_size/10,9*batch_size/10)
     loss = sigloss(target,output)
     return loss
+
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom net import Net\nfrom variables import *\nfrom train import train\nfrom test import test\nfrom loaders import test_loader,train_loader\nfrom functions import subset_data\nimport math\n#for batch, (data, target) in enumerate(train_loader):\n#    for batch, (data, target) in enumerate(test_loader):\ntorch.backends.cudnn.enabled = False\n\nusing_full_data = False\nloss_function_ids = {\"Mean Squared Error\":0,\"Significance Loss\":1}\n\n\n\ndef initilize():\n    torch.manual_seed(random_seed)\n    network = Net()\n    optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n    return network, optimizer\n\n\ndef train_and_test(loss_function_id):\n\n\n    network, optimizer = initilize()\n    test_loss_list = []\n    train_loss_list = []\n    correct = []\n    fp = []\n    tp = []\n    for epoch in range(1, n_epochs + 1):\n        print(\"Epoch number {}\".format(epoch))\n\n        for batch, (data, target) in enumerate(train_loader):\n            if using_full_data == False:\n                data,target = subset_data(data,target,background)\n            loss = train(network,optimizer,data,target,loss_function_id)\n            train_loss_list.append(loss)\n        print(\"Training Complete, loss:\")\n        #print(train_loss_list)\n\n        total_number_correct = 0\n        total_number = 0\n        false_positive_count = 0\n        true_positive_count = 0\n\n        for batch, (data, target) in enumerate(test_loader):\n            if using_full_data == False:\n                data,target = subset_data(data,target,background)\n            test_losses,batch_number_correct,batch_true_positive_count,batch_false_positive_count = test(network, data,target,loss_function_id)\n            test_loss_list.append(test_losses)\n            total_number += target.shape[0]\n            total_number_correct += batch_number_correct\n            true_positive_count += batch_true_positive_count\n            false_positive_count += batch_false_positive_count\n        correct.append(total_number_correct)\n        fp.append(false_positive_count)\n        tp.append(true_positive_count)\n        print(\"Testing Cmplete\")\n        if using_full_data:\n            print(\"Total number correct :{} ({}%) False positives:{} True Positives{}\".format(total_number_correct,100*total_number_correct/mnist_test_size,false_positive_count,true_positive_count))\n        else:\n            print(\"Total number correct :{} ({}%) False positives:{} True Positives{}\".format(total_number_correct,100*total_number_correct/(mnist_test_size/5),false_positive_count,true_positive_count))\n\n    torch.save(network.state_dict(), '/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/mse_20_partial_001.pth')\n    font1 = {'size':5}\n    plt.subplot(2, 2, 1)\n    plt.ylabel(\"Training Loss (per batch)\", fontdict = font1)\n    plt.title(\"Training\", fontdict = font1)\n    # plt.ylim(-10,10)\n    plt.plot(train_loss_list)\n\n\n    plt.subplot(2, 2, 2)\n    plt.xlabel(\"Epoch number\", fontdict = font1)\n    plt.ylabel(\"Test Loss\", fontdict = font1)\n    plt.title(\"Testing\", fontdict = font1)\n    plt.plot(test_loss_list)\n\n    print(test_loss_list)\n    significances = []\n    print(loss_function_id)\n\n    if loss_function_id == 1:\n        for i in range(len(test_loss_list)):\n            significances.append(math.sqrt(-1 * test_loss_list[i][0]))\n    elif loss_function_id ==0:\n        print(\"using seperate sig evaluation\")\n        if using_full_data:\n            total_number = mnist_test_size\n        else:\n            total_number = mnist_test_size/5\n        for i in range(len(tp)):\n            significances.append(tp[i]/math.sqrt(tp[i] + fp[i]))\n\n\n\n\n\n    plt.subplot(2, 2, 3)\n    plt.xlabel(\"Epoch number\", fontdict = font1)\n    plt.ylabel(\"Testing Significance\", fontdict = font1)\n    plt.title(\"Significance\", fontdict = font1)\n    plt.plot(significances)\n\n\n\n    plt.suptitle(\"MSE Loss 50 epochs, partial dataset\", fontdict = font1)\n    plt.savefig(\"/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/loss_graphs/mse_20_partial_001.png\")\n\n\ntrain_and_test(0)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/main.py	(date 1626892444506)
@@ -2,19 +2,15 @@
 import torch.optim as optim
 import matplotlib.pyplot as plt
 from net import Net
-from variables import *
-from train import train
 from test import test
-from loaders import test_loader,train_loader
-from functions import subset_data
+from train import train
+from variables import *
+from train_sigloss import train_sigloss
+from loaders import test_loader
 import math
-#for batch, (data, target) in enumerate(train_loader):
-#    for batch, (data, target) in enumerate(test_loader):
+
 torch.backends.cudnn.enabled = False
 
-using_full_data = False
-loss_function_ids = {"Mean Squared Error":0,"Significance Loss":1}
-
 
 
 def initilize():
@@ -24,94 +20,69 @@
     return network, optimizer
 
 
-def train_and_test(loss_function_id):
 
+def train_and_test():
+    torch.manual_seed(random_seed)
+    network = Net()
 
-    network, optimizer = initilize()
+    optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)
+
     test_loss_list = []
     train_loss_list = []
-    correct = []
-    fp = []
-    tp = []
+
     for epoch in range(1, n_epochs + 1):
+
         print("Epoch number {}".format(epoch))
+        train_losses = train(network,optimizer)
+
+        for i in range(len(train_losses)):
+            print(train_losses[i])
+            train_loss_list.append(train_losses[i])
+
+        print("Training Complete, losses {}".format(train_losses))
+        test_losses,total_number_correct,true_positive_count,false_positive_count,sample_output = test(network,-1)
+        for i in range(len(test_losses)):
+            test_loss_list.append(math.exp(test_losses[i]))
+
+        examples = enumerate(test_loader)
+        batch_idx, (example_data, example_targets) = next(examples)
+
+        #print(network(example_data))
 
-        for batch, (data, target) in enumerate(train_loader):
-            if using_full_data == False:
-                data,target = subset_data(data,target,background)
-            loss = train(network,optimizer,data,target,loss_function_id)
-            train_loss_list.append(loss)
-        print("Training Complete, loss:")
+
+
+        print("Testing Complete")
+        print(total_number_correct)
+        print("percent accuracy: {}, true positives {}, false positives {}".format(100*total_number_correct/10000,true_positive_count,false_positive_count))
+        torch.save(network.state_dict(), '/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/model.pth')
+        #print("LOSSES")
+        #print(train_losses)
         #print(train_loss_list)
-
-        total_number_correct = 0
-        total_number = 0
-        false_positive_count = 0
-        true_positive_count = 0
-
-        for batch, (data, target) in enumerate(test_loader):
-            if using_full_data == False:
-                data,target = subset_data(data,target,background)
-            test_losses,batch_number_correct,batch_true_positive_count,batch_false_positive_count = test(network, data,target,loss_function_id)
-            test_loss_list.append(test_losses)
-            total_number += target.shape[0]
-            total_number_correct += batch_number_correct
-            true_positive_count += batch_true_positive_count
-            false_positive_count += batch_false_positive_count
-        correct.append(total_number_correct)
-        fp.append(false_positive_count)
-        tp.append(true_positive_count)
-        print("Testing Cmplete")
-        if using_full_data:
-            print("Total number correct :{} ({}%) False positives:{} True Positives{}".format(total_number_correct,100*total_number_correct/mnist_test_size,false_positive_count,true_positive_count))
-        else:
-            print("Total number correct :{} ({}%) False positives:{} True Positives{}".format(total_number_correct,100*total_number_correct/(mnist_test_size/5),false_positive_count,true_positive_count))
-
-    torch.save(network.state_dict(), '/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/mse_20_partial_001.pth')
-    font1 = {'size':5}
-    plt.subplot(2, 2, 1)
-    plt.ylabel("Training Loss (per batch)", fontdict = font1)
-    plt.title("Training", fontdict = font1)
-    # plt.ylim(-10,10)
+        #print(test_losses)
+        #print(test_loss_list)
+    plt.subplot(1,2,1)
+    plt.xlabel("Batch # (15 batches per epoch)")
+    plt.ylabel("Ln of the Training Loss")
+    #plt.ylim(-10,10)
+
     plt.plot(train_loss_list)
-
+    plt.savefig("/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/matplotlib_output/lr0.001train.png")
 
-    plt.subplot(2, 2, 2)
-    plt.xlabel("Epoch number", fontdict = font1)
-    plt.ylabel("Test Loss", fontdict = font1)
-    plt.title("Testing", fontdict = font1)
-    plt.plot(test_loss_list)
+    #plt.subplot(1,2,2)
+    #plt.xlabel("Batch # (10 batches per epoch)")
+    #plt.ylabel("Ln of the Test Loss")
+    #plt.ylim(-10,10)
 
-    print(test_loss_list)
-    significances = []
-    print(loss_function_id)
+    #plt.plot(test_loss_list)
 
-    if loss_function_id == 1:
-        for i in range(len(test_loss_list)):
-            significances.append(math.sqrt(-1 * test_loss_list[i][0]))
-    elif loss_function_id ==0:
-        print("using seperate sig evaluation")
-        if using_full_data:
-            total_number = mnist_test_size
-        else:
-            total_number = mnist_test_size/5
-        for i in range(len(tp)):
-            significances.append(tp[i]/math.sqrt(tp[i] + fp[i]))
 
 
 
+    #plt.savefig("/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/matplotlib_output/lr0.001test_alone.png")
 
+train_and_test()
 
-    plt.subplot(2, 2, 3)
-    plt.xlabel("Epoch number", fontdict = font1)
-    plt.ylabel("Testing Significance", fontdict = font1)
-    plt.title("Significance", fontdict = font1)
-    plt.plot(significances)
 
 
 
-    plt.suptitle("MSE Loss 50 epochs, partial dataset", fontdict = font1)
-    plt.savefig("/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/loss_graphs/mse_20_partial_001.png")
 
-
-train_and_test(0)
Index: loaders.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nimport torchvision\nfrom variables import *\n\ntrain_loader = torch.utils.data.DataLoader(\n  torchvision.datasets.MNIST('/Users/mayabasu/pytorchdatasets', train=True, download=True,\n                             transform=torchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                               torchvision.transforms.Normalize(\n                                 (0.1307,), (0.3081,))\n                             ])),\n  batch_size=train_batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(\n  torchvision.datasets.MNIST('/Users/mayabasu/pytorchdatasets', train=False, download=True,\n                             transform=torchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                               torchvision.transforms.Normalize(\n                                 (0.1307,), (0.3081,))\n                             ])),\n  batch_size=test_batch_size, shuffle=True)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loaders.py b/loaders.py
--- a/loaders.py	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/loaders.py	(date 1626892444552)
@@ -3,19 +3,19 @@
 from variables import *
 
 train_loader = torch.utils.data.DataLoader(
-  torchvision.datasets.MNIST('/Users/mayabasu/pytorchdatasets', train=True, download=True,
+  torchvision.datasets.MNIST('/Users/noahomordia/pytorchdatasets', train=True, download=True,
                              transform=torchvision.transforms.Compose([
                                torchvision.transforms.ToTensor(),
                                torchvision.transforms.Normalize(
                                  (0.1307,), (0.3081,))
                              ])),
-  batch_size=train_batch_size, shuffle=True)
+  batch_size=train_batch_size, shuffle=False)
 
 test_loader = torch.utils.data.DataLoader(
-  torchvision.datasets.MNIST('/Users/mayabasu/pytorchdatasets', train=False, download=True,
+  torchvision.datasets.MNIST('/Users/noahomordia/pytorchdatasets', train=False, download=True,
                              transform=torchvision.transforms.Compose([
                                torchvision.transforms.ToTensor(),
                                torchvision.transforms.Normalize(
                                  (0.1307,), (0.3081,))
                              ])),
-  batch_size=test_batch_size, shuffle=True)
+  batch_size=test_batch_size, shuffle=False)
Index: rocmaker.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\n\n\nfrom functions import subset_data\nimport torch\nfrom test import test\nfrom net import Net\nfrom variables import *\nimport matplotlib.pyplot as plt\nfrom loaders import test_loader\n\ndef load_network(path):\n    network_state = torch.load(path)\n    network = Net()\n    network.load_state_dict(network_state)\n    return network\n\n\n\n\n\ndef make_roc_curve(cutoffs, network,filepath,loss_function_id,subset):\n\n    false_positives = []\n    true_positives = []\n\n\n    for i in range(len(cutoffs)):\n\n        for batch, (data, target) in enumerate(test_loader):\n            if subset:\n                data,target = subset_data(data,target,7)\n            test_losses,total_number_correct,true_positive_count,false_positive_count = test(network, data,target,loss_function_id,cutoffs[i],False)\n            print(\"fpc = {}, tpc = {}\".format(false_positive_count,true_positive_count))\n\n            false_positives.append(false_positive_count)\n            true_positives.append(true_positive_count)\n\n            if batch > 0:\n                print(\"set batch size to full testing set\")\n                break\n\n    print(false_positives)\n    print(true_positives)\n\n    false_positives_scaled = []\n    true_positives_scaled = []\n    for i in range(len(false_positives)):\n        false_positives_scaled.append(false_positives[i]/9000)\n\n    for i in range(len(true_positives)):\n        true_positives_scaled.append(true_positives[i]/1000)\n\n    plt.plot(false_positives_scaled,true_positives_scaled)\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    for i in range(0,len(cutoffs)):\n        plt.annotate(xy=[false_positives_scaled[i],true_positives_scaled[i]], s=cutoffs[i])\n    plt.savefig(filepath)\n    return\n\n\n\ncutoffs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nnetwork = load_network(\"/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/mse_20_partial.pth\")\n\nmake_roc_curve(cutoffs, network, \"/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/roc_curves/mse_20_partial.png\", 1,False)\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/rocmaker.py b/rocmaker.py
--- a/rocmaker.py	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/rocmaker.py	(date 1626892447413)
@@ -1,16 +1,11 @@
-
-
-
-from functions import subset_data
 import torch
 from test import test
 from net import Net
 from variables import *
 import matplotlib.pyplot as plt
-from loaders import test_loader
 
-def load_network(path):
-    network_state = torch.load(path)
+def load_network():
+    network_state = torch.load("/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/model.pth")
     network = Net()
     network.load_state_dict(network_state)
     return network
@@ -19,7 +14,7 @@
 
 
 
-def make_roc_curve(cutoffs, network,filepath,loss_function_id,subset):
+def make_roc_curve(cutoffs, network,filepath):
 
     false_positives = []
     true_positives = []
@@ -27,29 +22,24 @@
 
     for i in range(len(cutoffs)):
 
-        for batch, (data, target) in enumerate(test_loader):
-            if subset:
-                data,target = subset_data(data,target,7)
-            test_losses,total_number_correct,true_positive_count,false_positive_count = test(network, data,target,loss_function_id,cutoffs[i],False)
-            print("fpc = {}, tpc = {}".format(false_positive_count,true_positive_count))
-
-            false_positives.append(false_positive_count)
-            true_positives.append(true_positive_count)
-
-            if batch > 0:
-                print("set batch size to full testing set")
-                break
-
+
+        hits, correct, test_losses,num_times_signal_was_missed,num_times_signal_was_contaminated,num_times_signal_appears_in_dataset, false_positive_count,true_positive_count,deviations = test(network,test_batch_size,cutoffs[i],True)
+        print("fpc = {}, tpc = {}".format(false_positive_count,true_positive_count))
+        print("DEVIATIONS {}".format(deviations))
+        print("contaminated {} times, missed {} times, hit {} times".format(num_times_signal_was_contaminated,num_times_signal_was_missed, hits))
+        print(num_times_signal_appears_in_dataset)
+        false_positives.append(false_positive_count)
+        true_positives.append(true_positive_count)
     print(false_positives)
     print(true_positives)
 
     false_positives_scaled = []
     true_positives_scaled = []
     for i in range(len(false_positives)):
-        false_positives_scaled.append(false_positives[i]/9000)
+        false_positives_scaled.append(false_positives[i]/(10000-num_times_signal_appears_in_dataset))
 
     for i in range(len(true_positives)):
-        true_positives_scaled.append(true_positives[i]/1000)
+        true_positives_scaled.append(true_positives[i]/num_times_signal_appears_in_dataset)
 
     plt.plot(false_positives_scaled,true_positives_scaled)
     plt.ylabel('True Positive Rate')
@@ -63,7 +53,7 @@
 
 cutoffs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
 
-network = load_network("/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/neuralnets/mse_20_partial.pth")
+network = load_network()
 
-make_roc_curve(cutoffs, network, "/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/roc_curves/mse_20_partial.png", 1,False)
+make_roc_curve(cutoffs,network,"/Users/mayabasu/PycharmProjects/MNIST-test-neural-net2/matplotlib_output/plot2.png")
 
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.8 (MNIST-test-neural-net2)\" project-jdk-type=\"Python SDK\" />\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/.idea/misc.xml	(date 1626892447457)
@@ -1,4 +1,4 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.8 (MNIST-test-neural-net2)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: .idea/MNIST-test-neural-net2.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"PYTHON_MODULE\" version=\"4\">\n  <component name=\"NewModuleRootManager\">\n    <content url=\"file://$MODULE_DIR$\" />\n    <orderEntry type=\"jdk\" jdkName=\"Python 3.8 (MNIST-test-neural-net2)\" jdkType=\"Python SDK\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n  </component>\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/MNIST-test-neural-net2.iml b/.idea/MNIST-test-neural-net2.iml
--- a/.idea/MNIST-test-neural-net2.iml	(revision 5521e41e2450d96376f136a18e3498a19bbd31e1)
+++ b/.idea/MNIST-test-neural-net2.iml	(date 1626892447462)
@@ -2,7 +2,7 @@
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$" />
-    <orderEntry type="jdk" jdkName="Python 3.8 (MNIST-test-neural-net2)" jdkType="Python SDK" />
+    <orderEntry type="jdk" jdkName="Python 3.7" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
 </module>
\ No newline at end of file
